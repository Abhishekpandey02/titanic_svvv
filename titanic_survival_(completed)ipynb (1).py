# -*- coding: utf-8 -*-
"""TITANIC SURVIVAL (COMPLETED)ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1veySz5q8-OUnEPERIdxV-EJFom1mleiw

IMPORTING LIBRARIES
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
import streamlit as st
"""LOADING THE DATASET

"""

df = pd.read_csv("/content/Titanic-Dataset.csv")
df.head()

"""TO CHECK THE DATATYPE

"""

df.info()

"""TO CHECK THE NUMBER OF NULL VALUES"""

df.isnull().sum()

"""DROPPING THE CABIN COLUMN"""

df.drop(["Cabin"],axis=1,inplace=True)
df.info()

"""FILLING THE MISSING VALUE OF AGE WITH MEAN"""

df['Age'].fillna(df['Age'].mean(), inplace=True)
df.isnull().sum()

"""FILLING THE NULL VALUE OF EMBARKED"""

df['Embarked'].value_counts()
df["Embarked"].fillna("S",inplace=True)
df.isnull().sum()

df.info()

"""CHANGING THE DATATYPE OF AGE FROM FLOAT TO INTEGER DATATYPE"""

df['Age'] = df['Age'].astype(int)
df.info()

"""CREATING THE FUNCTION TO CALCULATE IQR"""

def winker(col):
  q1=df[col].quantile(.25)
  q3=df[col].quantile(.75)
  iqr=q3-q1
  uw=q3+1.5*iqr
  lw=q1-1.5*iqr
  return lw,uw

for i in ['Age','Parch','SibSp','Fare']:
  lw,uw=winker(i)
  df[i]=np.where(df[i]<lw,lw,df[i])
  df[i]=np.where(df[i]>uw,uw,df[i])

"""BOXPLOT OF AGE"""

sns.boxplot(df['Age'])

"""BOXPLOT OF PARCH"""

sns.boxplot(df['Parch'])

"""BOXPLOT OF FARE"""

sns.boxplot(df['Fare'])

"""BOXPLOT OF SIBSP

"""

sns.boxplot(df['SibSp'])

df.isnull().sum()

df.info()

"""CONVERTING REMAINING DATATYPE INTO INTEGER TYPE"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Sex'] = le.fit_transform(df['Sex'])
df['Embarked'] = le.fit_transform(df['Embarked'])
df['Name'] = le.fit_transform(df['Name'])
df['Ticket'] = le.fit_transform(df['Ticket'])
df.info()

"""CONVERTING FLOAT DATATYPE INTO INTEGER DATATYPE"""

for column in df.select_dtypes(include=['float']):
  df[column] = df[column].astype(int)
df.info()

"""SPLITTING THE DATA INTO 20:80 TESTING AND TRAINING"""

from sklearn.model_selection import train_test_split

X = df.drop('Survived', axis=1)
y = df['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""FEEDING THE TRAINING DATA INTO LINEAR REGRESSION MODEL"""

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

"""TESTING THE LINEAR REGRESSING MODEL USING TEST DATA"""

from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)
y_pred = [1 if val >= 0.5 else 0 for val in y_pred]
accuracy = accuracy_score(y_test, y_pred) * 100
print("Accuracy:", accuracy, "%")

"""TRAINING AND TESTING KNN MODEL"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)

knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred) * 100
print("Accuracy:", accuracy, "%")

"""TRAINING AND TESTING RANDOM FOREST MODEL"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, random_state=42)

rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred) * 100
print("Accuracy:", accuracy, "%")

"""TRAINING AND TESTING DECISION TREE MODEL"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)

dt.fit(X_train, y_train)

y_pred = dt.predict(X_test)

accuracy = accuracy_score(y_test, y_pred) * 100
print("Accuracy:", accuracy, "%")

# prompt: test the data in XG BOOST

!pip install xgboost

from xgboost import XGBClassifier

# Create an XGBoost classifier
xgb = XGBClassifier(random_state=42)

# Train the model
xgb.fit(X_train, y_train)

# Make predictions on the test set
y_pred = xgb.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred) * 100
print("Accuracy:", accuracy, "%")

!streamlit run "TITANIC SURVIVAL (COMPLETED).ipynb"
